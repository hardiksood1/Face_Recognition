# ğŸ¥ Face Detection & Recognition Video Processor

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![YOLOv8](https://img.shields.io/badge/YOLOv8-Ultralytics-green)](https://github.com/ultralytics/ultralytics)
[![Face Recognition](https://img.shields.io/badge/Face_Recognition-Dlib-orange)](https://github.com/ageitgey/face_recognition)
[![Gradio](https://img.shields.io/badge/Gradio-Web%20App-yellow)](https://gradio.app/)

A Python-based **video processing application** that detects faces using **YOLOv8**, recognizes known faces using [`face_recognition`](https://github.com/ageitgey/face_recognition), and provides a **GPU-accelerated Gradio interface** for uploading and processing videos.

---

## ğŸ”¹ Features

- ğŸš€ Real-time face detection with **YOLOv8**
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ Recognizes known faces from a folder of images
- âš¡ GPU acceleration (CUDA) for faster inference
- ğŸ¬ Annotated video output with bounding boxes and labels
- ğŸŒ User-friendly **Gradio web interface**
- âš™ï¸ Configurable tolerance & recognition model
- ğŸ¥ Supports `.mp4`, `.avi`, `.mov` formats

---

## ğŸ”¹ Folder Structure

face-detection-recognition/

â”œâ”€â”€ app.py # Main Gradio app

â”œâ”€â”€ config.py # Configuration (paths, output folder)

â”œâ”€â”€ face_utils.py # Face loading & recognition functions

â”œâ”€â”€ video_processor.py # Video processing logic

â”œâ”€â”€ known/ # Known faces folder

â”‚ â””â”€â”€ obama/ # Person subfolder with images

â”‚ â”œâ”€â”€ obama (1).jpg

â”‚ â”œâ”€â”€ obama (2).jpg

â”‚ â””â”€â”€ ...

â”œâ”€â”€ face.pt # YOLOv8 model for face detection

â”œâ”€â”€ output/ # Processed video output folder

â”œâ”€â”€ requirements.txt # Required Python packages

â””â”€â”€ .env # Environment variables

yaml
Copy
Edit

---

## ğŸ”¹ Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd face-detection-recognition
Create a virtual environment (recommended)

bash
Copy
Edit
python -m venv venv
source venv/bin/activate      # Linux / Mac
venv\Scripts\activate         # Windows
Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
Set up environment variables

Create a .env file:

env
Copy
Edit
FACE_MODEL_PATH=face.pt
KNOWN_PEOPLE_DIR=known
OUTPUT_DIR=output
ğŸ”¹ Usage
Run the Gradio App
bash
Copy
Edit
python app.py
The app will start a local web server.

Open the provided link in your browser.

Upload a video file and get the processed video with recognized faces.

Process Video via Script
python
Copy
Edit
from video_processor import process_video
from face_utils import load_known_faces
from config import KNOWN_PEOPLE_DIR, OUTPUT_DIR, FACE_MODEL_PATH
from ultralytics import YOLO
import torch

device = "cuda:0" if torch.cuda.is_available() else "cpu"
model = YOLO(FACE_MODEL_PATH).to(device)

known_face_encodings, known_face_names = load_known_faces(KNOWN_PEOPLE_DIR)

video_path = "input_video.mp4"
output_path = process_video(video_path, OUTPUT_DIR, model, known_face_encodings, known_face_names)
print("Processed video saved at:", output_path)
ğŸ”¹ Notes / Tips
âœ… Organize known faces in subfolders, one per person

âœ… Use YOLOv8 face.pt model (pretrained or custom-trained)

âœ… For best accuracy, use cnn model with GPU

âœ… Adjust tolerance in recognition if results are not accurate

âœ… Output videos are saved in the folder defined in .env

ğŸ”¹ Requirements
nginx
Copy
Edit
ultralytics
torch
opencv-python
face_recognition
numpy
gradio
python-dotenv
Install all dependencies via:

bash
Copy
Edit
pip install -r requirements.txt
ğŸ”¹ Screenshots (Example)
ğŸ“Œ Add your screenshots here after running the app!
Example:

bash
Copy
Edit
/screenshots/
   
   â”œâ”€â”€ upload_page.png
   
   â”œâ”€â”€ processing.png
   
   â””â”€â”€ output_video.png

ğŸ”¹ Acknowledgements
Ultralytics YOLOv8

face_recognition

Gradio

